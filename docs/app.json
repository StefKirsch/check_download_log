[{"name":"app.R","content":"library(shiny)\r\nlibrary(dplyr)\r\nlibrary(lubridate)\r\nlibrary(rstudioapi)\r\n\r\nsource(\"wave_helpers.R\")\r\n\r\nui <- fluidPage(\r\n\r\n  # App title\r\n  titlePanel(\"Download Log Validator\"),\r\n\r\n  # File input and check button\r\n  fileInput(\"file1\", \"Choose XLSX File\", accept = c(\".xlsx\")),\r\n  actionButton(\"check_file\", \"Check File\"),\r\n\r\n  # Text output for warnings and messages with CSS for line wrapping\r\n  tags$style(HTML(\"\r\n    #warnings {\r\n      white-space: pre-wrap;  /* Ensures line breaks are respected */\r\n      word-wrap: break-word;  /* Forces long words to break */\r\n    }\r\n  \")),\r\n\r\n  verbatimTextOutput(\"warnings\")\r\n)\r\n\r\nserver <- function(input, output) {\r\n\r\n  # Reactive expression to read the uploaded file when the button is clicked\r\n  observeEvent(input$check_file, {\r\n\r\n    # Ensure a file is selected\r\n    req(input$file1)\r\n\r\n    # Create a temporary file to store the console output\r\n    tmpfile <- tempfile()\r\n\r\n    # Open a connection to the temporary file\r\n    con <- file(tmpfile, open = \"wt\")\r\n\r\n    # Capture all console output (warnings, messages, and errors)\r\n    sink(con, type = \"output\")\r\n    sink(con, type = \"message\")\r\n\r\n    # Run the file reading and validation inside tryCatch\r\n    tryCatch({\r\n      # Read the file\r\n      path_download_log <- input$file1$datapath\r\n\r\n      # Read and validate download log\r\n      download_log <- read_download_log(path_download_log)\r\n\r\n      # If everything is correct, add success message\r\n      message(\"Download log is correct.\")\r\n\r\n    }, warning = function(w) {\r\n      # Capture warnings\r\n      message(paste(\"Warning:\", w$message))\r\n\r\n    }, error = function(e) {\r\n      # Capture errors\r\n      message(paste(\"Error:\", e$message))\r\n\r\n    }, finally = {\r\n      # Stop capturing the output and close the connection\r\n      sink(type = \"output\")\r\n      sink(type = \"message\")\r\n      close(con)\r\n\r\n      # Read the entire captured output\r\n      full_output <- paste(readLines(tmpfile), collapse = \"\\n\")\r\n\r\n      # Display the captured output in the UI\r\n      output$warnings <- renderText(full_output)\r\n\r\n      # Remove the temporary file\r\n      unlink(tmpfile)\r\n    })\r\n\r\n  })\r\n}\r\n\r\n\r\nshinyApp(ui = ui, server = server)\r\n","type":"text"},{"name":"wave_helpers.R","content":"#' Read Download Log from XLSX File\r\n#'\r\n#' This function reads the download log from an xlsx file based on hard-coded wave names.\r\n#' The wave names are used to access the individual sheets of the xlsx file.\r\n#' cleans the column names, and returns a named list of data frames, one per sheet/wave name.\r\n#'\r\n#' @param path_to_download_log Character. The file path to the download log in xlsx format.\r\n#'\r\n#' @return A named list of data frames, where each data frame corresponds to the wave name in the download log.\r\n#'\r\n#' @importFrom readxl read_xlsx\r\n#' @importFrom janitor clean_names\r\n#'\r\n#' @export\r\nread_download_log <- function(path_to_download_log) {\r\n\r\n  wave_names_in_download_log <- list(\r\n    \"VLF\" = \"LF\",\r\n    \"VLP\" = \"VITA+ LF\",\r\n    \"VMM\" = \"MM\",\r\n    \"VMP\" = \"VITA+ MM\"\r\n  )\r\n\r\n  download_log <- lapply(\r\n    names(wave_names_in_download_log),\r\n    function(sheet_name) {\r\n      readxl::read_xlsx(\r\n        path = path_to_download_log,\r\n        sheet = wave_names_in_download_log[[sheet_name]],\r\n        na = c( # all values that are considered NA and will be ignore for type guessing\r\n          \"x\",\r\n          \"datum open gezet\",\r\n          \"nog even naar kijken\",\r\n          \"Gedownload op nieuwe manier\",\r\n          \"nog niet geautoriseerd\",\r\n          \"gestopt met fitbit\",\r\n          \"Gestopt\",\r\n          \"open gezet\",\r\n          \"staat niet in MinIO\",\r\n          \"overleden\",\r\n          \"below add any other data values that should not be considered...\"\r\n        ),\r\n        .name_repair = \"unique_quiet\"\r\n      ) |>\r\n        janitor::clean_names() |> # removes spaces in column names\r\n        rename(study.number = studienummer) |> # translate studienummer\r\n        rename_with( # translate eind to end\r\n          .fn = ~ gsub(\r\n            pattern = \"eind\",\r\n            replacement = \"end\",\r\n            x = .x\r\n          ),\r\n          .cols = ends_with(\"_eind\")\r\n        ) |>\r\n        rename_with( # dot notation for column names\r\n          .fn = ~gsub(\r\n            pattern = \"_\",\r\n            replacement = \".\",\r\n            x = .x\r\n          )\r\n        ) |>\r\n        mutate(across( # convert everything to date.\r\n          -study.number,\r\n          ~ as.Date(.x, optional = TRUE) # return na if no date can be found\r\n        )) |>\r\n        janitor::remove_empty(which = c(\"rows\", \"cols\")) |>  # remove all NA rows and columns\r\n        rename_with(tolower)\r\n    }\r\n  ) |>\r\n    setNames(names(wave_names_in_download_log)) |> # set column names\r\n    bind_rows() |>\r\n    arrange(study.number) |>\r\n    add_spans() |>  # add wave duration spans\r\n    assert_download_log() # run assertive test suite\r\n\r\n  return(download_log)\r\n}\r\n\r\n\r\n#' Add Wave Label Column to fitbit dataframe\r\n#'\r\n#' This function takes a data frame containing fitbit observations (`df_data`) and another data frame\r\n#' containing wave information (`df_waves`), and adds a new column to `df_data` that indicates the\r\n#' wave ID for each observation based on its datetime. The wave ID is determined by the\r\n#' `assign_wave_id` function.\r\n#'\r\n#' @param df_data A data frame containing the observations with a 'Datetime' column and a 'study.number'\r\n#'                column.\r\n#' @param df_waves A data frame containing wave start and end times, with a 'study.number' column.\r\n#'\r\n#' @return A data frame identical to `df_data` but with an additional 'wave.id' column indicating\r\n#'         the wave ID for each observation.\r\n#'\r\n#' @details The function currently uses a row-wise operation which might be less efficient on very\r\n#'          large datasets. Future implementations might improve efficiency by replacing the start\r\n#'          and end columns with logical values to avoid the need for row-wise operations.\r\n#'\r\n#' @examples\r\n#' df_data_with_wave_id <- add_wave_label_col(df_data, df_waves)\r\n#'\r\n#' @export\r\n#' @importFrom dplyr left_join rowwise mutate ungroup\r\n#' @seealso \\code{\\link{assign_wave_id}}\r\nadd_wave_label_col <- function(df_data, df_waves, rm_outside_wave = TRUE) {\r\n\r\n  # short-circuit the function if df_waves is NULL\r\n  # This tells the function that there is no wave information to be processed\r\n\r\n  if (!is.null(df_waves)) {\r\n\r\n    message(paste0(Sys.time(),\": Labeling waves...\"))\r\n\r\n    start_end_pattern = \"w\\\\d+\\\\.(start|end)\"\r\n\r\n    df_data <- df_data |>\r\n      left_join(df_waves, by = \"study.number\") |> # Joining tables, keeping all observations in df_data\r\n      mutate(across( # slow, because it's probably not vectorized\r\n        .cols = matches(\"span.\"),\r\n        .fn = ~ Datetime %within% .x\r\n      )) |>\r\n      spans_to_in_week() |> # overwrite spans columns with wave ID or NA\r\n      mutate( # squeeze wave.id from the 5 columns, only keep the ones that are not missing\r\n        wave.id = coacross(matches(\"span.\")), # custom function that combines coalesce with across as a workaround, see function description\r\n        .after = study.number\r\n      ) |>\r\n      select(-contains(\"span\")) |> # remove temporary helper columns\r\n      replace_na(list(wave.id = 0)) |>\r\n      mutate(\r\n        wave_start_name_temp = paste0(\"w\", wave.id, \".start\"), # lookup column start\r\n        wave_end_name_temp = paste0(\"w\", wave.id, \".end\"), # lookup column end\r\n      )\r\n\r\n    # fast base R solution to lookup value of wX.start and wX.end from another column\r\n    # c.f. https://stackoverflow.com/questions/67678405/r-lookup-values-of-a-column-defined-by-another-columns-values-in-mutate\r\n    df_data_wo_lookup_vars <- df_data |>\r\n      as.data.frame() |> # not tibble!\r\n      select(-c(wave_start_name_temp, wave_end_name_temp))\r\n\r\n    df_data_wo_lookup_vars$wave.start <- df_data_wo_lookup_vars[cbind(\r\n      seq_len(nrow(df_data_wo_lookup_vars)), # row index\r\n      match(df_data$wave_start_name_temp, names(df_data_wo_lookup_vars)) # column index\r\n    )]\r\n\r\n    df_data_wo_lookup_vars$wave.end <- df_data_wo_lookup_vars[cbind(\r\n      seq_len(nrow(df_data_wo_lookup_vars)), # row index\r\n      match(df_data$wave_end_name_temp, names(df_data_wo_lookup_vars)) # column index\r\n    )]\r\n\r\n    # a bit of final housekeeping...\r\n    df_data_wo_lookup_vars <- df_data_wo_lookup_vars |>\r\n      select(-matches(start_end_pattern)) |>  # remove temporary helper columns\r\n      select(study.number, wave.id, wave.start, wave.end, everything()) |>  # reorder columns\r\n      mutate( # add wave duration\r\n        wave.duration.mins = difftime(wave.end, wave.start, units = \"mins\")\r\n      )\r\n\r\n    if (rm_outside_wave) {\r\n      df_data_wo_lookup_vars <- df_data_wo_lookup_vars |> filter(wave.id > 0)\r\n    }\r\n\r\n    message(paste0(Sys.time(),\": Done\"))\r\n\r\n    return(df_data_wo_lookup_vars)\r\n  } else {\r\n    # short-circuit\r\n    return(df_data)\r\n  }\r\n\r\n}\r\n\r\n\r\n# Add span column form start and end columns\r\nadd_spans <- function(downLoad_log) {\r\n\r\n  for (i in seq(1, 5)) {\r\n    span_col <- paste0(\"span.w\",i)\r\n    start_col <- paste0(\"w\",i,\".start\")\r\n    end_col <- paste0(\"w\",i,\".end\")\r\n\r\n    # add intervals\r\n    # skip intervals where we don't have both a start and end date\r\n    if (start_col %in% colnames(downLoad_log) & end_col %in% colnames(downLoad_log)) {\r\n      downLoad_log <- downLoad_log |>\r\n        mutate(\r\n          # sym seems to be needed\r\n          !!span_col := interval(!!sym(start_col), !!sym(end_col)),\r\n          .keep = \"all\"\r\n        )\r\n    }\r\n  }\r\n\r\n  return(downLoad_log)\r\n}\r\n\r\n\r\n# Overwrites the spans columns added by add_spans()\r\n# If the observation falls in the span, it's replaced with the wave id\r\n# if not, the value is set to NA\r\nspans_to_in_week <- function(downLoad_log) {\r\n\r\n  for (i in seq(1, 5)) {\r\n    span_col <- paste0(\"span.w\",i)\r\n\r\n    # skip intervals that don' exist\r\n    if (span_col %in% colnames(downLoad_log)) {\r\n      downLoad_log <- downLoad_log |>\r\n        mutate(\r\n          !!span_col := if_else(!!sym(span_col), i, NA),\r\n          .keep = \"all\"\r\n        )\r\n    }\r\n  }\r\n\r\n  return(downLoad_log)\r\n}\r\n\r\n\r\n# Workaround for problem with coalesce and across\r\n# c.f. https://github.com/tidyverse/funs/issues/54\r\ncoacross <- function(...) {\r\n  coalesce(!!!across(...))\r\n}\r\n\r\n\r\n# Get actual download log by identifying periods where the participants\r\n# wore the fitbit the most within the date ranges given in the original\r\n# download log.\r\n# The desired period to look for the densest data is `wave_duration_days`\r\n# Runs get_optimal_wave_dates_per_group() per study_number of a dataframe\r\n# that is sampled per day.\r\n# Then cleans up the result to get a new_download log in the same format\r\n# as the original one that can then be used\r\nget_actual_download_log <- function(df_daily) {\r\n\r\n  wave_duration_days <- 14\r\n\r\n  df_daily |>\r\n    group_by(study.number, wave.id) %>%\r\n    # get optimal wave dates BY GROUP\r\n    # this requires that the groups are passed into get_optimal_wave_dates()\r\n    # in sequence\r\n    # Just calling the function would not do the operation by group\r\n    # ind of weird that this function is called \"do()\"\r\n    # It is somewhat deprecated, but the alternatives seems excessively clunky\r\n    do(get_optimal_wave_dates_per_group(., wave_duration_days)) |>\r\n    ungroup() |>\r\n    # Do some manipulation to restore the original download_log format\r\n    # Note: All wave ranges that were missing in daily_steps_hr\r\n    # turn up as NA now.\r\n    # arrange by wave.id so that the date columns end up in the right order\r\n    arrange(\r\n      wave.id\r\n    ) |>\r\n    # concatenate wave ids to naming to reflect what we got from original download log\r\n    mutate(\r\n      wave.id = paste0(\"w\", wave.id)  # Prefix wave.id with 'w' for better column naming\r\n    ) |>\r\n    pivot_wider(\r\n      names_from = wave.id,\r\n      values_from = c(wave.start.actual, wave.end.actual),\r\n      names_sep = \" \" # Separate the wave id prefix and date type with a space for clarity\r\n    ) %>%\r\n    # rename start dates\r\n    rename_with(\r\n      ~ gsub(\r\n        pattern = \"wave.start.actual w([1-9])\",\r\n        replacement = \"w\\\\1.start\",\r\n        x = .\r\n      ),\r\n      starts_with(\"wave.start.actual\")\r\n    ) %>%\r\n    # rename end dates\r\n    rename_with(\r\n      ~ gsub(\r\n        pattern = \"wave.end.actual w([1-9])\",\r\n        replacement = \"w\\\\1.end\",\r\n        x = .\r\n      ),\r\n      starts_with(\"wave.end.actual\")\r\n    ) |>\r\n    arrange(study.number) |>\r\n    add_spans() # add wave duration spans\r\n\r\n}\r\n\r\n\r\n# detect the date windows where the most data was found\r\n# intended to be called per group with `do()`\r\nget_optimal_wave_dates_per_group <- function(df, wave_duration_days) {\r\n  # function to get all 14-day periods with maximum `n.value.`\r\n\r\n  start_date <- df$wave.start[1]\r\n  end_date <- df$wave.end[1]\r\n\r\n  # account for the fact that some waves are shorter than wave_duration_days\r\n  latest_start_date <- if (end_date - start_date >= days(wave_duration_days - 1)) {\r\n    start_date + days(wave_duration_days - 1)\r\n  } else {\r\n    end_date\r\n  }\r\n\r\n  all_possible_starts <- seq(\r\n    from = start_date,\r\n    to = latest_start_date,\r\n    by = \"day\"\r\n  )\r\n\r\n  # Calculate sum of `n.value.` for each 14-day period\r\n  # sapply loops over every element in all_possible_starts and\r\n  # per start date returns the sum of recorded observations for the\r\n  # following 2 week period\r\n  period_sums <- sapply(all_possible_starts, function(start_date) {\r\n    df |>\r\n      # filter for candidate period\r\n      filter(Date >= start_date & Date <= start_date + days(wave_duration_days) - 1) |>\r\n      # select only number of observations\r\n      select(starts_with(\"n.value.\")) |>\r\n      # Calculate sum of observations\r\n      sum()\r\n  })\r\n\r\n  # Identify the period with the maximum `n.value.`\r\n  max_periods <- which.max(period_sums)\r\n  start_date_max <- all_possible_starts[max_periods]\r\n\r\n  # Return the start and end dates of the optimal period\r\n  tibble(\r\n    wave.start.actual = start_date_max,\r\n    wave.end.actual = start_date_max + days(wave_duration_days - 1)\r\n  )\r\n}\r\n\r\n\r\nassert_download_log <- function(downLoad_log) {\r\n  max_wave_length_weeks <- 4\r\n  max_wave_length_seconds <- 4 * 7 * 24 * 60 * 60\r\n\r\n  # Do some checks\r\n  assertr_errors <- downLoad_log |>\r\n    # Check that every study number is only mentioned once\r\n    assertr::assert(\r\n      assertr::is_uniq,\r\n      study.number,\r\n      error_fun = assertr::error_append,\r\n      description = \"One or more study numbers are mentioned more than once.\"\r\n    ) |>\r\n    # Check for reverse intervals, i.e. where the start date happens after the end date\r\n    assertr::assert(\r\n      predicate = assertr::within_bounds(0,Inf),\r\n      starts_with(\"span.w\"),\r\n      error_fun = assertr::error_append,\r\n      description = \"The wave(s) start date is after the wave end date.\"\r\n    ) |>\r\n    # Check for waves that last longer than three weeks\r\n    assertr::assert(\r\n      predicate = assertr::within_bounds(0, max_wave_length_seconds),\r\n      starts_with(\"span.w\"),\r\n      error_fun = assertr::error_append,\r\n      description = paste(\r\n        \"One or more waves seem to be longer than\",\r\n        max_wave_length_weeks,\r\n        \"weeks.\"\r\n      )\r\n    ) |>\r\n    attr(\"assertr_errors\")\r\n\r\n  message_text <- character()\r\n\r\n  for (assertr_error in assertr_errors) {\r\n    index <- assertr_error$error_df$index\r\n    study_number <- paste(unique(downLoad_log$study.number[index]), collapse = \", \" )\r\n    column <- assertr_error$error_df$column\r\n    description <- assertr_error$description\r\n\r\n    message_text <- glue::glue(paste(\r\n      \"Warning:\",\r\n      \"Assertion failed for study number\",\r\n      \"{study_number}\",\r\n      \"in column\",\r\n      \"\\\"{column}\\\"\",\r\n      \"- \",\r\n      \"{description}\",\r\n      \"\\n\\n\"\r\n    )) |> unique() # message is repeated per conflicting row\r\n\r\n    message(message_text)\r\n  }\r\n\r\n  if (length(message_text)) {\r\n    stop(\"The download log excel sheet failed at least one test. Please correct them first.\")\r\n  }\r\n\r\n  return(downLoad_log)\r\n}","type":"text"}]
